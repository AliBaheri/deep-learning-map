# AI Safety Glossary

Here is an incredible [visualisation of the AI Safety Research Landscape (Future of Life Institute)](https://futureoflife.org/landscape/).

## Approaches

- Inverse Reinforcement Learning
- Cooperative Inverse Reinforcement Learning
- Multi-Armed Bandits

## Problems
- Negative side effects
- Reward Hacking
- Scalable Oversight
- Safe exploration
- Robustness to distributional shift
- Absent Supervisor
- Wireheading
- Interruptibility
- Corrigibility
- Containment
- Value learning

## Other
- 'MIRI Agenda'
